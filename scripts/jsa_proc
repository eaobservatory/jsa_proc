#!/usr/bin/env python2

# Copyright (C) 2014 Science and Technology Facilities Council.
# Copyright (C) 2016-2023 East Asian Observatory.
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

"""jsa_proc - JSA processing tracking system tool

Usage:
    jsa_proc clean [-v | -q] [--dry-run] input [--count <number>] [--include-error] [--include-processed] [--task <task>...]
    jsa_proc clean [-v | -q] [--dry-run] output [--count <number>] [--task <task>...] [--no-cadc-check] [--include-error] [--include-ingestion]
    jsa_proc clean [-v | -q] [--dry-run] scratch [--count <number>] [--include-error] [--include-ingestion] [--include-processed]
    jsa_proc diskusage [-v | -q] input [--task <task>...]
    jsa_proc diskusage [-v | -q] output [--task <task>...]
    jsa_proc dws [-v | -q] compare <file>...
    jsa_proc dws [-v | -q] get [--parents] <file>...
    jsa_proc dws [-v | -q] put <file>...
    jsa_proc etransfer [-v | -q] [--dry-run] [--force] --job-id <id>
    jsa_proc etransfer [-v | -q] [--dry-run] --poll
    jsa_proc etransfer [-v | -q] --query --job-id <id>
    jsa_proc fetch [-v | -q] [--job-id <id>] [--force] [--replaceparent] [--task <task>...]
    jsa_proc fetch [-v | -q] [--dry-run] output [--force] --job-id <id>
    jsa_proc fetch [-v | -q] [--dry-run] output [--force] [--task <task>...] [--location <location>]
    jsa_proc ingest [-v | -q] [--dry-run] [--force] --job-id <id>
    jsa_proc ingest [-v | -q] [--dry-run] --task <task>... [--location <location>]
    jsa_proc inputs [-v | -q] --job-id <id>
    jsa_proc namecheck [-v | -q] file <file>
    jsa_proc namecheck [-v | -q] directory <directory>
    jsa_proc namecheck [-v | -q] output --task <task>... --outfile <file>
    jsa_proc poll [-v | -q]
    jsa_proc ptransfer [-v | -q] [--dry-run] [--stream <stream>]
    jsa_proc ptransfer [-v | -q] [--dry-run] [--clean]
    jsa_proc query [-v | -q] (jcmtinfo | caom2 | caom2file | common | ompstatus | dws | adtap) <search>
    jsa_proc rawingest [-v | -q] [--dry-run] --obsid <obsid>
    jsa_proc rawingest [-v | -q] [--dry-run] --poll --date-start <ut-date> [--date-end <ut-date>] [--quick] [--no-transfer-check]
    jsa_proc reset [-v | -q] [--dry-run] [--force] --task <task>... [--date-start <ut-date>] [--date-end <ut-date>] [--instrument <instrument>] [--state <state>]
    jsa_proc revalidate [-v | -q] [--dry-run] (output) --job-id <id>
    jsa_proc revalidate [-v | -q] [--dry-run] (output) [--task <task>...] [--location <location>]
    jsa_proc run [-v | -q] [--job-id <id>] [--force] [--task <task>...]
    jsa_proc search_log [-v | -q] --task <task>... [--project <project>] [--after-context <lines>] [--state <state>] [--notes] <search>
    jsa_proc transfer [-v | -q] [--dry-run] [--task <task>...]
    jsa_proc unauthorized [-v | -q] [--check-at-cadc]
    jsa_proc --help [<helptopic>]

Options:
    --help, -h                 Show usage information.
    --verbose, -v              Print debugging information.
    --quiet, -q                Omit informational messages.
    --dry-run, -n              Do not actually peform the action.

    --job-id, -j <id>          Identifier of job on which to work.
    --location, -l <location>  Job location, e.g. JAC, CADC.

    --after-context <lines>    Number of lines of context to show.
    --count, -c <number>       Number of jobs to process.
    --check-at-cadc            Test whether files are at CADC.
    --date-start <ut-date>     Date at which to start.
    --date-end <ut-date>       Date at which to end.
    --force, -f                Skip initial state check.
    --include-error            Include jobs in the error state.
    --include-ingestion        Include jobs in the waiting to ingest state.
    --include-processed        Include jobs in the processed state.
    --instrument <instrument>  Name of instrument.
    --replaceparent            Force recopying parent jobs into input folder
    --outfile <file>           File into which to write output.
    --obsid <obsid>            Observation identifier (OBSID header).
    --no-cadc-check            Skip checks for files being at CADC.
    --parents, -p              Create parent directories.
    --poll                     Poll a system for state updates.
    --project <project>        OMP project identifier.
    --state <state name>       Job state.
    --stream <stream>          P-transfer stream ("new" or "replace").
    --tag <tag>                Select jobs by tag.
    --task, -t <task>...       Select jobs for a particular task.
    --quick                    Use simpler but less thorough database query.
    --notes                    Show notes.

For more information about a particular command, please use:

    jsa_proc --help COMMAND
"""

from __future__ import print_function, division, absolute_import

import functools
import logging
import os
import sys
import textwrap

from docopt import docopt

from jsa_proc.config import get_database
from jsa_proc.error import CommandError
from jsa_proc.state import JSAProcState

script_name = 'jsa_proc'
commands = {}
logger = logging.getLogger(script_name)

integer_arguments = (
    '--job-id', '--count',
    '--date-start', '--date-end',
    '--after-context',
)

optional_repeating_arguments = (
    '--task',
)


class CommandContinue(Exception):
    pass


def main():
    """Main routine for the jsa_proc tool."""

    args = docopt(__doc__, help=False)

    # Determine logging level from the --quiet and --verbose options.
    loglevel = logging.INFO

    if args['--verbose']:
        loglevel = logging.DEBUG
    elif args['--quiet']:
        loglevel = logging.WARNING

    logging.basicConfig(level=loglevel)

    try:
        # Process integer arguments.
        for integer_argument in integer_arguments:
            if args[integer_argument] is not None:
                try:
                    args[integer_argument] = int(args[integer_argument])
                except ValueError:
                    raise CommandError('Option {0} must be an integer'.
                                       format(integer_argument))

        # Process optional repeating arguments
        # for which we want `None` instead of [].
        for repeating_argument in optional_repeating_arguments:
            if [] == args[repeating_argument]:
                args[repeating_argument] = None

        # Is this a help request?
        if args['--help']:
            help(args)

        else:
            # Determine which sub-command to perform.
            for (command, func) in commands.items():
                if args.get(command):
                    try:
                        logger.debug('Running %s subcommand', command)
                        func(args)
                        break
                    except CommandContinue:
                        pass
            else:
                raise CommandError('Failed to find sub-command to run')

    except CommandError as e:
        # If a known error happened, display its message and exit with
        # bad status.
        print('{0}: {1}'.format(script_name, e.args[0]), file=sys.stderr)
        sys.exit(1)

    else:
        # Otherwise exit with good status.
        sys.exit(0)


def command(f):
    """Decorator which adds a function to the commands dictionary.

    Note that the docstring of the function will be printed by the
    help function when help is requested for that command.  The
    docstring should be formatted such that textwrap.dedent can
    un-indent it (i.e. the first line should have the same indentation
    as the others.
    """

    commands[f.__name__[:-1] if f.__name__.endswith('_') else f.__name__] = f
    return f


def command_confirm(prompt):
    from jsa_proc.action.util import yes_or_no_question

    if not yes_or_no_question(prompt):
        sys.exit(0)


@command
def clean(args):
    """
    Attempts to free disk space by deleting old directories which are
    no longer required.

    By default, scratch directories for jobs which are in an error
    state are retained to aid in debugging.  They can be removed
    by including the --include-error option.  Similarly scratch
    directories for jobs in the "waiting for ingestion" state can be
    removed with the --include-ingestion option.
    """

    if args['input']:
        from jsa_proc.action.clean import clean_input
        clean_input(count=args['--count'], dry_run=args['--dry-run'],
                    task=args['--task'],
                    include_error=args['--include-error'],
                    include_processed=args['--include-processed'])

    elif args['output']:
        if args['--include-error']:
            command_confirm('Clean output for jobs in error states?')
        if args['--include-ingestion']:
            command_confirm('Clean output which is awaiting ingestion?')

        from jsa_proc.action.clean import clean_output
        clean_output(count=args['--count'], dry_run=args['--dry-run'],
                     task=args['--task'], no_cadc_check=args['--no-cadc-check'],
                     include_error=args['--include-error'],
                     include_ingestion=args['--include-ingestion'])

    elif args['scratch']:
        from jsa_proc.action.clean import clean_scratch
        clean_scratch(count=args['--count'], dry_run=args['--dry-run'],
                      include_error=args['--include-error'],
                      include_ingestion=args['--include-ingestion'],
                      include_processed=args['--include-processed'])

    else:
        raise CommandError('Did not recognise clean type')


@command
def diskusage(args):
    """
    Displays disk usage by task.
    """

    if args['input']:
        from jsa_proc.action.datafile_handling import disk_usage_input
        disk_usage_input(tasks=args['--task'])

    elif args['output']:
        from jsa_proc.action.datafile_handling import disk_usage_output
        disk_usage_output(tasks=args['--task'])

    else:
        raise CommandError('Did not recognise disk usage type')


@command
def dws(args):
    """
    Get or put files to CADC data web service.
    """

    action_compare = False

    if args['query']:
        # Continue to the "query dws" command.
        raise CommandContinue()
    elif args['compare']:
        action_compare = True
    elif args['get']:
        action_fetch = True
    elif args['put']:
        action_fetch = False
    else:
        raise CommandError('Did not recognise dws command')

    from jsa_proc.cadc.fetch import fetch_cadc_file, fetch_cadc_file_info, \
        put_cadc_file
    from jsa_proc.files import get_md5sum

    for pathname in args['<file>']:
        (dirname, filename) = os.path.split(pathname)

        if action_compare:
            if not os.path.exists(pathname):
                raise CommandError(
                    'File "{}" does not exist'.format(filename))

            cadc_file_info = fetch_cadc_file_info(filename)
            if cadc_file_info is None:
                raise CommandError(
                    'File "{}" is not in the archive'.format(filename))

            md5sum = get_md5sum(pathname)

            cadc_md5sum = cadc_file_info['content-md5']
            if md5sum == cadc_md5sum:
                print('File "{}" matches the archive: {} == {}'.format(
                    filename, md5sum, cadc_md5sum))

            else:
                raise CommandError(
                    'File "{}" does not match the archive: {} != {}'.format(
                        filename, md5sum, cadc_md5sum))

        elif action_fetch:
            if os.path.exists(pathname):
                raise CommandError(
                    'File "{}" already exists'.format(filename))

            if not os.path.exists(dirname):
                if args['--parents']:
                    logger.info('Creating directory "{}"'.format(dirname))
                    os.makedirs(dirname)

                else:
                    raise CommandError(
                        'Directory "{}" does not exist'.format(dirname))

            logger.info('Getting file "{}"'.format(filename))
            fetch_cadc_file(filename, dirname, suffix='')

        else:
            if not os.path.exists(pathname):
                raise CommandError(
                    'File "{}" does not exist'.format(filename))

            if fetch_cadc_file_info(filename) is not None:
                raise CommandError(
                    'File "{}" is already in the archive'.format(filename))

            logger.info('Putting file "{}"'.format(filename))
            put_cadc_file(filename, dirname)


@command
def etransfer(args):
    """
    Copy files into the e-transfer system, to poll the e-transfer system
    for status updates or to query the e-transfer state of job.

    The --query option is interactive: if rejected files are found then
    it will prompt for whether to delete those files and for whether
    to re-try the transfer.  The query results table indicates whether
    the file is in progress (True), rejected (False) or not found
    (None), and also whether the file is in AD (True or False).
    """

    from jsa_proc.cadc.etransfer import etransfer_poll_output, \
        etransfer_query_output, etransfer_send_output

    if args['--poll']:
        etransfer_poll_output(dry_run=args['--dry-run'])

    elif args['--query']:
        etransfer_query_output(args['--job-id'])

    else:
        etransfer_send_output(args['--job-id'], dry_run=args['--dry-run'],
                              force=args['--force'])


@command
def fetch_(args):
    """
    Fetch input or output data for a job.

    Without the "output" option:
    Looks at a job in the queued state, assembles the data for it,
    and then advances the job to the waiting state.

    If the --job-id command line argument is not used, this will run on
    the highest priority job labelled to be reduced at the JAC and in the
    missing state.

    With the "output" option:
    Retrieves output data files for the given job, or the highest
    priority job found with the given search criteria.
    """

    from jsa_proc.action.fetch import fetch, fetch_output

    if args['output']:
        fetch_output(job_id=args['--job-id'],
                     location=args['--location'], task=args['--task'],
                     dry_run=args['--dry-run'], force=args['--force'])
    else:

        fetch(job_id=args['--job-id'], force=args['--force'],
              replaceparent=args['--replaceparent'],
              task=args['--task'])


def help(args):
    """Display usage and help information.

    If no additional option is given, then general usage information is
    displayed.  Otherwise help information for the specified command is
    shown, provided that the command exists.  This consists of usage
    patterns from this file's docstring, plus the docstring of the
    command's function.
    """

    topic = args['<helptopic>']

    if topic is None:
        # General usage information.
        print(__doc__)

    else:
        # Find the documentation for a command.
        if topic in commands:
            print('Usage:')
            for line in __doc__.splitlines():
                if line.startswith('    jsa_proc ' + topic):
                    print(line)

            print('')
            print('Description:')
            print('')
            print(textwrap.dedent(commands[topic].__doc__).strip())
            print('')

        else:
            raise CommandError('No help available for {0}'.format(topic))


@command
def ingest(args):
    """
    Ingest a output from one or more jobs into CAOM-2.

    Location is "JAC" by default.
    """

    from jsa_proc.cadc.ingest import ingest_output

    ingest_output(args['--job-id'],
                  location=('JAC' if args['--location'] is None
                            else args['--location']),
                  task=args['--task'],
                  dry_run=args['--dry-run'],
                  force=args['--force'])


@command
def inputs(args):
    """
    List the input files of the given job.
    """

    from jsa_proc.action.datafile_handling import check_data_already_present

    db = get_database()

    inputs = check_data_already_present(args['--job-id'], db)

    for input_ in inputs:
        print(input_)


@command
def namecheck(args):
    """
    Run a name check on files listed in the processing database.

    Currently this supports the following otions:

    * Checking the names of job output files, with the jobs selected by
      task name.

      File names which fail name checking are written to the specified file.

    * Checking a single file name, or the names of files in a given directory.

      File names which fail are logged.

      File names which pass the name check are logged in verbose mode.
    """

    if args['output']:
        from jsa_proc.action.namecheck import namecheck_output

        namecheck_output(task=args['--task'], outfile=args['--outfile'])

    elif args['directory']:
        from jsa_proc.action.namecheck import namecheck_directory

        namecheck_directory(args['<directory>'])

    elif args['file']:
        from jsa_proc.action.namecheck import namecheck_file

        namecheck_file(args['<file>'][0])

    else:
        raise CommandError('Did not recognise namecheck action')


@command
def poll(args):
    """
    This command will carry out simple state changes for JAC jobs in the
    database configured in the JSAProc configuration file.
    """

    from jsa_proc.admin.statemachine import JSAProcStateMachine

    # Get the database specified in the config file.
    db = get_database()

    # Get the state machine.
    sm = JSAProcStateMachine(db)

    # Poll the JAC jobs.
    status = sm.poll_jac_jobs()

    # Return a status of 1 if status is not True.
    if not status:
        raise CommandError('Errors were encountered during state poll')


@command
def ptransfer(args):
    """
    Attempt to put files from the e-transfer directories into
    the archive at CADC.  This emulates the behavior of CADC's
    e-transfer system.

    In dry run mode, a stream ("new" or "replace") must be specified,
    otherwise this is optional and both streams will be processed.

    In clean-up mode (with the --clean option), look for orphaned
    "proc" directories for which the corresponding p-transfer process
    is no longer running.  Files will be moved back to their original
    stream directories and the "proc" directories deleted.
    """

    from jsa_proc.cadc.ptransfer import ptransfer_poll, ptransfer_clean_up

    if args['--clean']:
        ptransfer_clean_up(dry_run=args['--dry-run'])
    else:
        ptransfer_poll(stream=args['--stream'], dry_run=args['--dry-run'])


@command
def query(args):
    """
    Utility to test the various internal query methods.

    jcmtinfo:   queries the jcmtinfo web service for a given filename
                pattern, which can include a % wildcard symbol.

    caom2:      queries CAOM-2 via tap for a given obsid pattern.

    caom2file:  queries CAOM-2 via tap for a given filename.

    common:     queries the COMMON table for the given obsid.

    ompstatus:  retrieves the status of an obsid from the OMP.

    dws:        retrieves information from the CADC data web service
                for a given file.

    adtap:      queries AD via TAP
    """

    search = args['<search>']

    if args['caom2']:
        from jsa_proc.cadc.tap import CADCTap
        caom2 = CADCTap()
        for (obsid, planeid) in sorted(caom2.obsids_by_pattern(
                search.lower(), with_productid=True)):
            print(obsid, planeid)

    elif args['caom2file']:
        from jsa_proc.cadc.tap import CADCTap
        caom2 = CADCTap()
        print(repr(caom2.check_files([search])))

    elif args['jcmtinfo']:
        from jsa_proc.cadc.files import CADCFiles
        ad = CADCFiles()
        for file in sorted(ad.files_by_pattern(search)):
            print(file)

    elif args['ompstatus']:
        from omp.obs.state import OMPState
        from jsa_proc.omp.config import get_omp_database
        ompdb = get_omp_database()
        state = ompdb.get_obsid_status(search)
        print('Status: ' +
              ('NULL' if state is None else OMPState.get_name(state)))

    elif args['common']:
        from jsa_proc.omp.config import get_omp_database
        ompdb = get_omp_database()
        common = ompdb.get_obsid_common(search)
        for field in sorted(common._fields):
            print('{0}: {1!s}'.format(field, getattr(common, field)))

    elif args['dws']:
        from jsa_proc.cadc.fetch import fetch_cadc_file_info
        info = fetch_cadc_file_info(search)
        if info is None:
            print('Not found')
        else:
            for key in sorted(info.keys()):
                print('{0}: {1}'.format(key, repr(info[key])))

    elif args['adtap']:
        from jsa_proc.cadc.adtap import ADTap
        ad = ADTap()
        for entry in ad.search_file(search):
            print('{} {}'.format(entry.md5, entry.id_))

    else:
        raise CommandError('Did not recognise query type')


@command
def rawingest(args):
    """
    Ingest raw observations into CAOM-2.

    Supports the following modes:

        * Ingesting a single observation, the OBSID of
          which must be given via the --obsid option.

        * Searching for observations in a given date range
          (--date-start to optional --date-end) via the --poll
          option.  The --quick option can be used in this case
          to perform a simpler check for only observations which
          have not be ingested successfully before.
    """

    from jsa_proc.cadc.rawingest import ingest_raw_observation, \
        poll_raw_ingestion

    if args['--obsid']:
        ingest_raw_observation(args['--obsid'], dry_run=args['--dry-run'])

    elif args['--poll']:
        poll_raw_ingestion(date_start=args['--date-start'],
                           date_end=args['--date-end'],
                           quick=args['--quick'],
                           no_transfer_check=args['--no-transfer-check'],
                           dry_run=args['--dry-run'])

    else:
        raise CommandError('Unknown raw ingestion operation')


@command
def reset(args):
    """
    Reset the status of a set of jobs.

    Jobs are selected by task, state, date range and optional instrument name.
    The state of matching jobs is reset to "Unknown".  Jobs in active
    states are not reset unless the --force option is given.
    """

    from jsa_proc.action.reset import reset_jobs

    reset_jobs(task=args['--task'],
               date_start=args['--date-start'],
               date_end=args['--date-end'],
               instrument=args['--instrument'],
               state=args['--state'],
               force=args['--force'],
               dry_run=args['--dry-run'])


@command
def revalidate(args):
    """
    Re-validate jobs.

    Currently only output validation is supported.
    """

    if args['output']:
        from jsa_proc.action.validate import validate_output

        db = get_database()

        if args['--job-id'] is not None:
            validate_output(args['--job-id'], db, dry_run=args['--dry-run'])

        else:
            for job in db.find_jobs(task=args['--task'],
                                    location=args['--location'],
                                    state=JSAProcState.STATE_POST_RUN):
                validate_output(job.id, db, dry_run=args['--dry-run'])

    else:
        raise CommandError('Did not recognise re-validation type')


@command
def run(args):
    """
    Run a job locally and mark the state appropriately. If the
    option --job-id is not given, it will run the highest priority job
    marked to be performed at the JAC and already in the waiting state.
    """

    from jsa_proc.action.run import run_job

    run_job(job_id=args['--job-id'], force=args['--force'],
            task=args['--task'])


@command
def search_log(args):
    """
    Search log files for the given pattern.
    """

    from jsa_proc.action.log import search_log_files

    search_log_files(
        pattern=args['<search>'], filename_pattern='^oracdr',
        task=args['--task'], project=args['--project'],
        state=args['--state'], after_context=args['--after-context'],
        notes=args['--notes'])


@command
def transfer(args):
    """
    This command will check for jobs in the "Processed" state and
    attempt to transfer their output files.
    """

    from jsa_proc.action.transfer import transfer_poll

    # Get the database specified in the config file.
    db = get_database()

    # Poll the JAC jobs.
    status = transfer_poll(db, task=args['--task'], dry_run=args['--dry-run'])

    # Return a status of 1 if status is not True.
    if not status:
        raise CommandError('Errors were encountered during transfer poll')


@command
def unauthorized(args):
    """
    Investigate jobs which failed to fetch due to "unauthorized" errors.
    """

    from jsa_proc.action.unauthorized import investigate_unauthorized_errors

    investigate_unauthorized_errors(
        location='JAC',
        check_at_cadc=args['--check-at-cadc'])


if __name__ == '__main__':
    main()
